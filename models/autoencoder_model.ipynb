{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Autoencoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code in this notebook creates a convolutional neural network autoencoder model for reproducing artwork images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Input\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 20\n",
    "image_dimension = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_img = Input(shape=(image_dimension, image_dimension, 3))\n",
    "\n",
    "# Encoding layers\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name='encoded_layer')(x)\n",
    "\n",
    "# Decoding layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Instanstiate Model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View parameter summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Images for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for images\n",
    "base_directory = './autoencoder/'\n",
    "training_directory = os.path.join(base_directory, 'train/')\n",
    "validation_directory = os.path.join(base_directory, 'validate/')\n",
    "test_directory = os.path.join(base_directory, 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample files used to train model drawn from all images\n",
    "sample_size = 10000\n",
    "allimage_directory = './autoencoder/all_data/'\n",
    "total_image_count = len([name for name in os.listdir(allimage_directory)])\n",
    "all_image_names = os.listdir(allimage_directory)\n",
    "sample_indices = np.random.randint(0, total_image_count, size=sample_size)\n",
    "training_sample_indices = sample_indices[:int(sample_size*.8)]\n",
    "validation_sample_indices = sample_indices[int(sample_size*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images into training and validation folders\n",
    "from shutil import copy2\n",
    "for training_sample_index in training_sample_indices:\n",
    "    copy2(allimage_directory + all_image_names[training_sample_index], training_directory + all_image_names[training_sample_index])\n",
    "for validation_sample_index in validation_sample_indices:\n",
    "    copy2(allimage_directory + all_image_names[validation_sample_index], validation_directory + all_image_names[validation_sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators to process images\n",
    "# Rescale by 1./255\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_generator = datagen.flow_from_directory(\n",
    "        training_directory,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        batch_size=batch_size,\n",
    "        # No classes since unsupervised\n",
    "        class_mode='input')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_directory,\n",
    "        target_size=(image_dimension, image_dimension),\n",
    "        batch_size=batch_size,\n",
    "        # No classes since unsupervised\n",
    "        class_mode='input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping if epochs don't change loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples for calculating number of steps\n",
    "training_samples = training_generator.samples\n",
    "validation_samples = validation_generator.samples\n",
    "\n",
    "# Number of steps\n",
    "training_steps = training_samples / batch_size\n",
    "validation_steps = validation_samples / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = autoencoder.fit_generator(\n",
    "      training_generator,\n",
    "      steps_per_epoch=training_steps,\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_steps,\n",
    "      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and Narrow Encoded Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "autoencoder.save('./autoencoder/models/autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature extractor\n",
    "feature_extractor = \\\n",
    "    Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoded_layer').output)\n",
    "feature_extractor.save('./autoencoder/models/feature_extractor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss for training and validation sets\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
